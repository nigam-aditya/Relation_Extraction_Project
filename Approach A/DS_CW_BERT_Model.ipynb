{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6029a31f955a484fa30f40333f92cbb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce8140e1231c430da247141bc5f90565",
              "IPY_MODEL_626cf946438c490d86a4b86563735e4c",
              "IPY_MODEL_7ab6b1c340264769bbe8d5f331149339"
            ],
            "layout": "IPY_MODEL_adf1a8d8f6cc4cb09d8150ff22e3c6f8"
          }
        },
        "ce8140e1231c430da247141bc5f90565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe896c8807c348beac2928a033df1a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_3e9564656f344ca6a943d73b3c84160e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "626cf946438c490d86a4b86563735e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d64b570565e84e4a90fdb9ca760602b8",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4169152f8aa4af293b37744a7003a84",
            "value": 48
          }
        },
        "7ab6b1c340264769bbe8d5f331149339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32f3b18dfc444f1a9c11f76f32bb2ff",
            "placeholder": "​",
            "style": "IPY_MODEL_3ed0189164c64b94b0d63697e7e706da",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.46kB/s]"
          }
        },
        "adf1a8d8f6cc4cb09d8150ff22e3c6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe896c8807c348beac2928a033df1a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e9564656f344ca6a943d73b3c84160e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d64b570565e84e4a90fdb9ca760602b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4169152f8aa4af293b37744a7003a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a32f3b18dfc444f1a9c11f76f32bb2ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed0189164c64b94b0d63697e7e706da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "368df55e449a4613ad44904174d5e08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37f02e9f4ec54a36bcde560e2ef95dde",
              "IPY_MODEL_0bf5ca13bb7c453ead6c4fb853dc2e0a",
              "IPY_MODEL_747d2b210a9e4f7f864583fc69043f22"
            ],
            "layout": "IPY_MODEL_6561be2e283b43dd868d393c3e9eae56"
          }
        },
        "37f02e9f4ec54a36bcde560e2ef95dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16276f7c236044b586b86f05fa327b0b",
            "placeholder": "​",
            "style": "IPY_MODEL_c5435eac6d36499fbd1085c83917aa18",
            "value": "vocab.txt: 100%"
          }
        },
        "0bf5ca13bb7c453ead6c4fb853dc2e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8986eb721150416699f9a75ef0152813",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_970dd50e01e94c5ab90d963045f03f54",
            "value": 231508
          }
        },
        "747d2b210a9e4f7f864583fc69043f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4472f2bf224f46bdbb563c0b6057d7",
            "placeholder": "​",
            "style": "IPY_MODEL_85ce39d434744094bf3f61c7a2f2bd73",
            "value": " 232k/232k [00:00&lt;00:00, 2.48MB/s]"
          }
        },
        "6561be2e283b43dd868d393c3e9eae56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16276f7c236044b586b86f05fa327b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5435eac6d36499fbd1085c83917aa18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8986eb721150416699f9a75ef0152813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "970dd50e01e94c5ab90d963045f03f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d4472f2bf224f46bdbb563c0b6057d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ce39d434744094bf3f61c7a2f2bd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0199d78429d4df4a4c1ce8755c5745f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_634d6dd50b774df3aa1059d35f1a3294",
              "IPY_MODEL_6fd1301408c84b5484c099f7d22606ac",
              "IPY_MODEL_cec561707f8f4bd0ba2a9b67266bc404"
            ],
            "layout": "IPY_MODEL_075ad689f1804037a7dcbd42cf5d5ffd"
          }
        },
        "634d6dd50b774df3aa1059d35f1a3294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e662b6eab74abba80fcf358ece32cc",
            "placeholder": "​",
            "style": "IPY_MODEL_00cffaeecdf34a5cab550fc850919e8c",
            "value": "tokenizer.json: 100%"
          }
        },
        "6fd1301408c84b5484c099f7d22606ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0019048a01704c1b8a79a41a98d2ed4f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52133fc978f04c0fa3f9cd4ccd2f67e7",
            "value": 466062
          }
        },
        "cec561707f8f4bd0ba2a9b67266bc404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97fb5474b5554df68343f53ecd0d07a2",
            "placeholder": "​",
            "style": "IPY_MODEL_25ae950fa65242729e22feebed606ad7",
            "value": " 466k/466k [00:00&lt;00:00, 9.31MB/s]"
          }
        },
        "075ad689f1804037a7dcbd42cf5d5ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e662b6eab74abba80fcf358ece32cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00cffaeecdf34a5cab550fc850919e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0019048a01704c1b8a79a41a98d2ed4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52133fc978f04c0fa3f9cd4ccd2f67e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97fb5474b5554df68343f53ecd0d07a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ae950fa65242729e22feebed606ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a6a2d3a4ef345bbb67b10ae173a08c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6da4bba5d0b4accb798c9d39e65a280",
              "IPY_MODEL_db140a43412b4a9dafdc35f384f3b8b4",
              "IPY_MODEL_460aa29e3cab4aa2bf9f7afc9a503858"
            ],
            "layout": "IPY_MODEL_2794c766947b4479aa455945c1911fda"
          }
        },
        "b6da4bba5d0b4accb798c9d39e65a280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8c0a1f6bb74eaca747d2cb5fcd2021",
            "placeholder": "​",
            "style": "IPY_MODEL_0d65c3463c564234b66a8db261bcceeb",
            "value": "config.json: 100%"
          }
        },
        "db140a43412b4a9dafdc35f384f3b8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dd91f2288514d44b1c4087cc6ef3344",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b68824a3d111474584ee53f77a8e1688",
            "value": 570
          }
        },
        "460aa29e3cab4aa2bf9f7afc9a503858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e52385150e741668c66d73d6842a2e7",
            "placeholder": "​",
            "style": "IPY_MODEL_70b7a9d8d63842ca92f16077739bff2d",
            "value": " 570/570 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "2794c766947b4479aa455945c1911fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8c0a1f6bb74eaca747d2cb5fcd2021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d65c3463c564234b66a8db261bcceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dd91f2288514d44b1c4087cc6ef3344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68824a3d111474584ee53f77a8e1688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e52385150e741668c66d73d6842a2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b7a9d8d63842ca92f16077739bff2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4838d098f6cd4efc881379497988edeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee061e85713047849e4fdcf31287e4f6",
              "IPY_MODEL_5f373218a5384f1f8d291a6e5d3a8e4d",
              "IPY_MODEL_2e7e6848fd7942fb8f7990c5a5275d1f"
            ],
            "layout": "IPY_MODEL_bdcbd04002d34053aeb5d682512294cf"
          }
        },
        "ee061e85713047849e4fdcf31287e4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883700350e544e9581282426201b8149",
            "placeholder": "​",
            "style": "IPY_MODEL_e954e8acccf04d1f9297f83b882b52fe",
            "value": "model.safetensors: 100%"
          }
        },
        "5f373218a5384f1f8d291a6e5d3a8e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa3283265c584ff8a8f289d924fa138a",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c19b4cabcb24f31bfe4a4aabb0a473a",
            "value": 440449768
          }
        },
        "2e7e6848fd7942fb8f7990c5a5275d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9b3511817e84f7baaf7872ee9bbf154",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd5c0df8fa64af89ad28f096ff6b330",
            "value": " 440M/440M [00:02&lt;00:00, 214MB/s]"
          }
        },
        "bdcbd04002d34053aeb5d682512294cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883700350e544e9581282426201b8149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e954e8acccf04d1f9297f83b882b52fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa3283265c584ff8a8f289d924fa138a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c19b4cabcb24f31bfe4a4aabb0a473a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9b3511817e84f7baaf7872ee9bbf154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd5c0df8fa64af89ad28f096ff6b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing Packages"
      ],
      "metadata": {
        "id": "7AMXRqRUWvB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from textblob import TextBlob\n",
        "import requests\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "stop_words = stopwords.words('english')\n",
        "words = set(nltk.corpus.words.words())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J9yKRkVo0B7",
        "outputId": "38028dca-09d1-467f-be88-15897c759316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading function"
      ],
      "metadata": {
        "id": "is0HERm8XLEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def load_data_label(path):\n",
        "      temp_data = []\n",
        "      lines = [line.strip() for line in open(path)]\n",
        "      for idx in range(0, len(lines), 4):\n",
        "          id = lines[idx].split(\"\\t\")[0]\n",
        "          relation = lines[idx + 1]\n",
        "\n",
        "          sentence = lines[idx].split(\"\\t\")[1][1:-1]\n",
        "          sentence = sentence.replace(\"<e1>\", \" _e1_ \").replace(\"</e1>\", \" _/e1_ \")\n",
        "          sentence = sentence.replace(\"<e2>\", \" _e2_ \").replace(\"</e2>\", \" _/e2_ \")\n",
        "          sentence = sentence.replace(\"<e1>\", \"<e1> \").replace(\"</e1>\", \" </e11>\")\n",
        "          sentence = sentence.replace(\"<e2>\", \"<e2> \").replace(\"</e2>\", \" </e22>\")\n",
        "\n",
        "          tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "          tokens.remove('_/e1_')\n",
        "          tokens.remove('_/e2_')\n",
        "\n",
        "          e1 = tokens.index(\"_e1_\")\n",
        "          del tokens[e1]\n",
        "          element1=tokens[e1]\n",
        "          e2 = tokens.index(\"_e2_\")\n",
        "          del tokens[e2]\n",
        "          element2=tokens[e2]\n",
        "          sentence = \" \".join(tokens)\n",
        "          temp_data.append([id, sentence, e1, element1, e2, element2, relation])\n",
        "      df = pd.DataFrame(data=temp_data, columns=[\"id\", \"sentence\", \"e1_position\",\"element1\", \"e2_position\",\"element2\", \"class\"])\n",
        "      #print (df)\n",
        "      labelsMapping = {'Other': 0,'Message-Topic(e1,e2)': 1, 'Message-Topic(e2,e1)': 2,\n",
        "                      'Product-Producer(e1,e2)': 3, 'Product-Producer(e2,e1)': 4,\n",
        "                      'Instrument-Agency(e1,e2)': 5, 'Instrument-Agency(e2,e1)': 6,\n",
        "                      'Entity-Destination(e1,e2)': 7, 'Entity-Destination(e2,e1)': 8,\n",
        "                      'Cause-Effect(e1,e2)': 9, 'Cause-Effect(e2,e1)': 10,\n",
        "                      'Component-Whole(e1,e2)': 11, 'Component-Whole(e2,e1)': 12,\n",
        "                      'Entity-Origin(e1,e2)': 13, 'Entity-Origin(e2,e1)': 14,\n",
        "                      'Member-Collection(e1,e2)': 15, 'Member-Collection(e2,e1)': 16,\n",
        "                      'Content-Container(e1,e2)': 17, 'Content-Container(e2,e1)': 18}\n",
        "      df['tag'] = [labelsMapping[r] for r in df['class']]\n",
        "      #print(df)\n",
        "      x_sentence = df['sentence'].tolist()\n",
        "\n",
        "      #Label Data\n",
        "      y = df['tag']\n",
        "      return df"
      ],
      "metadata": {
        "id": "AeABhosWpMYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlQ7iBg6oYUJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"large_ds_df_exported.csv\") #  (for training data we have already loaded while creation in Distant Supervision file)\n",
        "\n",
        "path_to_test_file = \"/content/TEST_FILE.txt\"\n",
        "df_test = load_data_label(path_to_test_file) # (for the test data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning"
      ],
      "metadata": {
        "id": "mFdw22fOXoqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessor(sentence):\n",
        "\n",
        "    sentence = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r'\\d+','', sentence)\n",
        "    sentence = sentence.replace(\"user\", \"\")\n",
        "    return  sentence\n",
        "\n",
        "def clean_text(df):\n",
        "\n",
        "    train_cleaned = df['sentence'].apply(preprocessor)\n",
        "    df['sentence'] = train_cleaned.apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "X_zNiHeoov53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input format\n",
        "df['sentence'] = df['sentence'] + \" \" + df['element1'] + \" \" + df['element2']\n",
        "df_test['sentence'] = df_test['sentence'] + \" \" + df_test['element1'] + \" \" + df_test['element2']\n",
        "\n",
        "train_cleaned = clean_text(df)\n",
        "test_cleaned = clean_text(df_test)"
      ],
      "metadata": {
        "id": "YyPZxdHDo-7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing torch and transformers"
      ],
      "metadata": {
        "id": "GNVXo-IRXsvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYeHw6--pgTZ",
        "outputId": "93be37e6-ec53-4015-e12a-2809f88acf40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rqoh2mUpiyz",
        "outputId": "d9b8bb1e-e687-440d-c397-d905f4f97699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer"
      ],
      "metadata": {
        "id": "3VlOrd2UXxDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# loading BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#  tokenizing set of texts\n",
        "def Input_embeddings(data,length):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sentence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=length,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True\n",
        "            )\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "E5y7etOZpwQk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6029a31f955a484fa30f40333f92cbb4",
            "ce8140e1231c430da247141bc5f90565",
            "626cf946438c490d86a4b86563735e4c",
            "7ab6b1c340264769bbe8d5f331149339",
            "adf1a8d8f6cc4cb09d8150ff22e3c6f8",
            "fe896c8807c348beac2928a033df1a5c",
            "3e9564656f344ca6a943d73b3c84160e",
            "d64b570565e84e4a90fdb9ca760602b8",
            "c4169152f8aa4af293b37744a7003a84",
            "a32f3b18dfc444f1a9c11f76f32bb2ff",
            "3ed0189164c64b94b0d63697e7e706da",
            "368df55e449a4613ad44904174d5e08f",
            "37f02e9f4ec54a36bcde560e2ef95dde",
            "0bf5ca13bb7c453ead6c4fb853dc2e0a",
            "747d2b210a9e4f7f864583fc69043f22",
            "6561be2e283b43dd868d393c3e9eae56",
            "16276f7c236044b586b86f05fa327b0b",
            "c5435eac6d36499fbd1085c83917aa18",
            "8986eb721150416699f9a75ef0152813",
            "970dd50e01e94c5ab90d963045f03f54",
            "2d4472f2bf224f46bdbb563c0b6057d7",
            "85ce39d434744094bf3f61c7a2f2bd73",
            "b0199d78429d4df4a4c1ce8755c5745f",
            "634d6dd50b774df3aa1059d35f1a3294",
            "6fd1301408c84b5484c099f7d22606ac",
            "cec561707f8f4bd0ba2a9b67266bc404",
            "075ad689f1804037a7dcbd42cf5d5ffd",
            "11e662b6eab74abba80fcf358ece32cc",
            "00cffaeecdf34a5cab550fc850919e8c",
            "0019048a01704c1b8a79a41a98d2ed4f",
            "52133fc978f04c0fa3f9cd4ccd2f67e7",
            "97fb5474b5554df68343f53ecd0d07a2",
            "25ae950fa65242729e22feebed606ad7",
            "5a6a2d3a4ef345bbb67b10ae173a08c4",
            "b6da4bba5d0b4accb798c9d39e65a280",
            "db140a43412b4a9dafdc35f384f3b8b4",
            "460aa29e3cab4aa2bf9f7afc9a503858",
            "2794c766947b4479aa455945c1911fda",
            "fd8c0a1f6bb74eaca747d2cb5fcd2021",
            "0d65c3463c564234b66a8db261bcceeb",
            "4dd91f2288514d44b1c4087cc6ef3344",
            "b68824a3d111474584ee53f77a8e1688",
            "3e52385150e741668c66d73d6842a2e7",
            "70b7a9d8d63842ca92f16077739bff2d"
          ]
        },
        "outputId": "349e4804-aa69-4fc1-b248-e7b2cbbacbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6029a31f955a484fa30f40333f92cbb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "368df55e449a4613ad44904174d5e08f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0199d78429d4df4a4c1ce8755c5745f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a6a2d3a4ef345bbb67b10ae173a08c4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = np.concatenate([train_cleaned.sentence.values, test_cleaned.sentence.values])\n",
        "sentences_encoded = [tokenizer.encode(sent, add_special_tokens=True, truncation=True) for sent in sentences]\n",
        "max_length = max([len(sent) for sent in sentences_encoded])\n",
        "print('Max length: ', max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxJQ0D5IpzSq",
        "outputId": "e344b77c-8bf1-44fb-d9e6-c5c2dd9c072d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_cleaned.sentence[0]]\n",
        "token_ids = list(Input_embeddings(data,max_length)[0].squeeze().numpy())\n",
        "print('Original: ', train_cleaned.sentence[0])\n",
        "print('Token IDs: ', token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_yMHb8Ap4tA",
        "outputId": "67f09727-71de-40cf-dcef-f5eb037a028f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  the system described above has its greatest application arrayed configuration antenna elements configuration elements\n",
            "Token IDs:  [101, 1996, 2291, 2649, 2682, 2038, 2049, 4602, 4646, 9140, 2098, 9563, 13438, 3787, 9563, 3787, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the training and validation data for model"
      ],
      "metadata": {
        "id": "frxLH7WNX27L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
        "    train_cleaned['sentence'].values,\n",
        "    train_cleaned['tag'].values,\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "train_input_ids, train_attention_masks = Input_embeddings(train_sentences, max_length)\n",
        "val_input_ids, val_attention_masks = Input_embeddings(val_sentences, max_length)\n",
        "\n",
        "# Convert the labels to tensors.\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "val_data = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "id": "cHs5YVc8rFiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Weighting"
      ],
      "metadata": {
        "id": "XhH8ulrjX-U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "# Calculate class counts\n",
        "class_counts = Counter(train_cleaned['tag'])\n",
        "\n",
        "# Exclude class 8 from the class counts\n",
        "class_counts_without_8 = {k: v for k, v in class_counts.items() if k != 8}\n",
        "\n",
        "# Calculate class weights (inverse of class frequencies) excluding class 8\n",
        "class_weights_without_8 = torch.tensor([1.0 / class_counts_without_8[i] for i in range(19) if i != 8], dtype=torch.float32)\n",
        "\n",
        "# Normalize the weights so they sum to 1\n",
        "class_weights_without_8 = class_weights_without_8 / class_weights_without_8.sum()\n",
        "\n",
        "# Create a tensor for all classes, initially setting weight for class 8 to 0\n",
        "class_weights = torch.zeros(19, dtype=torch.float32)\n",
        "for i in range(19):\n",
        "    if i != 8:\n",
        "        class_weights[i] = class_weights_without_8[i if i < 8 else i - 1]\n",
        "\n",
        "# manual adjust for class 8 by adjusting other classes as well\n",
        "class_weights[8]=0.02\n",
        "class_weights[14]=0.0786\n",
        "class_weights[18]=0.0916\n",
        "print(class_weights)\n",
        "print(class_weights.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYSGBO7BJWVx",
        "outputId": "3a856c05-89a1-48eb-e4f1-c457bc882404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0079, 0.0229, 0.0822, 0.0351, 0.0263, 0.1742, 0.0397, 0.0106, 0.0200,\n",
            "        0.0602, 0.0268, 0.0268, 0.0252, 0.0198, 0.0786, 0.1840, 0.0265, 0.0415,\n",
            "        0.0916])\n",
            "tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function"
      ],
      "metadata": {
        "id": "hWBmbryvYBPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = class_weights.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "metadata": {
        "id": "qj1JDJGAMc2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics"
      ],
      "metadata": {
        "id": "G3ZdMN84YDkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# Function to calculate the F1 score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def flat_f1(preds, labels):\n",
        "    # Flatten the predictions and labels\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    # Exclude the 'Other' class (label 0) and calculate F1 for the remaining 18 classes\n",
        "    f1 = f1_score(labels_flat, pred_flat, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], average='macro')\n",
        "    return f1"
      ],
      "metadata": {
        "id": "LxH0QMIdgtiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Setup and Initial Training"
      ],
      "metadata": {
        "id": "cvhqo6EYYHcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels=19,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    eps=1e-8,\n",
        ")\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,  # Default value in run_glue.py\n",
        "    num_training_steps=total_steps,\n",
        ")\n",
        "# Training loop\n",
        "import random\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Move batch tensors to the device\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = outputs.logits  # Extract logits from the model output\n",
        "\n",
        "        # Calculate loss using the custom loss function with class weights\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "    eval_accuracy, eval_f1 = 0, 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        # Move batch tensors to the device\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Forward pass\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate metrics\n",
        "        eval_accuracy += flat_accuracy(logits, labels)\n",
        "        eval_f1 += flat_f1(logits, labels)\n",
        "\n",
        "    print(f\"Validation Accuracy: {eval_accuracy / len(val_dataloader)}\")\n",
        "    print(f\"Validation F1 Score: {eval_f1 / len(val_dataloader)}\")\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxS_Hf5gg-u_",
        "outputId": "3abc352c-bed5-4d0a-e3f7-defa410238d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.12\n",
            "  Training epoch took: 0:05:31\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.5047516648168701\n",
            "Validation F1 Score: 0.36637412203449926\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.00\n",
            "  Training epoch took: 0:05:32\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.7177788568257492\n",
            "Validation F1 Score: 0.4961861796073782\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epoch took: 0:05:32\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.783157602663707\n",
            "Validation F1 Score: 0.5309102625481112\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epoch took: 0:05:32\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8066731409544949\n",
            "Validation F1 Score: 0.5411454268713259\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Testing"
      ],
      "metadata": {
        "id": "M1lkLdbsYO13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "\n",
        "# Tokenize the test sentences and prepare the test DataLoader\n",
        "test_input_ids, test_attention_masks = Input_embeddings(test_cleaned['sentence'].values, max_length)\n",
        "test_labels = torch.tensor(test_cleaned['tag'].values)\n",
        "\n",
        "# Create the TensorDataset\n",
        "test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "# Create the DataLoader\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)"
      ],
      "metadata": {
        "id": "BPXLb8XPwwJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test evaluation loop\n",
        "model.eval()\n",
        "test_accuracy, test_f1 = 0, 0\n",
        "nb_test_steps = 0\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    # Move batch to GPU\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "\n",
        "    # Calculate predictions\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct_predictions = torch.sum(preds == b_labels).item()\n",
        "    total_predictions = len(b_labels)\n",
        "    tmp_test_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Calculate f1,  Exclude 'Other' class\n",
        "    tmp_test_f1 = f1_score(\n",
        "        b_labels.cpu().numpy(),\n",
        "        preds.cpu().numpy(),\n",
        "        average='macro',         # Macro-averaged F1 score\n",
        "        labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
        "    )\n",
        "\n",
        "\n",
        "    test_accuracy += tmp_test_accuracy\n",
        "    test_f1 += tmp_test_f1\n",
        "    nb_test_steps += 1\n",
        "\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy / nb_test_steps}\")\n",
        "print(f\"Test F1 Score (excluding 'Other' class): {test_f1 / nb_test_steps}\")"
      ],
      "metadata": {
        "id": "hPVdcccyrO2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1006812e-5e5a-478d-f21c-fac205d8575e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7436992900608519\n",
            "Test F1 Score (excluding 'Other' class): 0.5315555577320283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "AAluGh01Rrln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "id": "9g_G7q-UR1iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna import Trial\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set a fixed random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial: Trial):\n",
        "    # Hyperparameters to tune\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 2e-5, 8e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.025)\n",
        "\n",
        "    # Print the current combination of hyperparameters\n",
        "    print(f\"\\nTrial {trial.number}:\")\n",
        "    print(f\"  Learning Rate: {learning_rate}\")\n",
        "    print(f\"  Batch Size: {batch_size}\")\n",
        "    print(f\"  Weight Decay: {weight_decay}\")\n",
        "\n",
        "    # Update the DataLoader with the new batch size\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Reinitialize the model, optimizer, and scheduler with the new hyperparameters\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=19,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        eps=1e-8,  # Fixed epsilon\n",
        "        weight_decay=weight_decay,  # Tuned weight decay\n",
        "    )\n",
        "    total_steps = len(train_dataloader) * 3  # Fixed epochs = 3\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.1 * total_steps),  # 10% warmup steps\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    for epoch_i in range(3):  # Fixed epochs = 3\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"  Epoch {epoch_i + 1}: Training Loss = {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    eval_accuracy, eval_f1 = 0, 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "        eval_accuracy += flat_accuracy(logits, labels)\n",
        "        eval_f1 += flat_f1(logits, labels)\n",
        "\n",
        "    # Compute average validation metrics\n",
        "    avg_eval_accuracy = eval_accuracy / len(val_dataloader)\n",
        "    avg_eval_f1 = eval_f1 / len(val_dataloader)\n",
        "\n",
        "    # Print the validation metrics\n",
        "    print(f\"  Validation Accuracy: {avg_eval_accuracy:.4f}\")\n",
        "    print(f\"  Validation F1 Score: {avg_eval_f1:.4f}\")\n",
        "\n",
        "    # Return the metric to optimize\n",
        "    return avg_eval_f1\n",
        "\n",
        "# Create an Optuna study and optimize\n",
        "study = optuna.create_study(direction=\"maximize\")  # Maximize F1 score\n",
        "study.optimize(objective, n_trials=12)  # Limit to 15 combinations\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"\\nBest hyperparameters:\", study.best_params)\n",
        "print(\"Best F1 score:\", study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POdfbui3Z_--",
        "outputId": "e189e0cb-a772-4e86-bf92-9b6aab52aec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 02:57:57,758] A new study created in memory with name: no-name-a2c4faef-d630-4605-abc1-b8597395e324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 0:\n",
            "  Learning Rate: 4.2972789809091055e-05\n",
            "  Batch Size: 32\n",
            "  Weight Decay: 0.019859829933948636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.9133\n",
            "  Epoch 2: Training Loss = 0.5611\n",
            "  Epoch 3: Training Loss = 0.2344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 03:14:54,758] Trial 0 finished with value: 0.5680511576090561 and parameters: {'learning_rate': 4.2972789809091055e-05, 'batch_size': 32, 'weight_decay': 0.019859829933948636}. Best is trial 0 with value: 0.5680511576090561.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8597\n",
            "  Validation F1 Score: 0.5681\n",
            "\n",
            "Trial 1:\n",
            "  Learning Rate: 4.9623507005211336e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.02422743737693746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.0766\n",
            "  Epoch 2: Training Loss = 0.7022\n",
            "  Epoch 3: Training Loss = 0.3122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 03:31:07,845] Trial 1 finished with value: 0.6832869192391429 and parameters: {'learning_rate': 4.9623507005211336e-05, 'batch_size': 64, 'weight_decay': 0.02422743737693746}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8336\n",
            "  Validation F1 Score: 0.6833\n",
            "\n",
            "Trial 2:\n",
            "  Learning Rate: 2.2506750661077515e-05\n",
            "  Batch Size: 16\n",
            "  Weight Decay: 0.016141925324305778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.9611\n",
            "  Epoch 2: Training Loss = 0.6912\n",
            "  Epoch 3: Training Loss = 0.3279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 03:49:43,906] Trial 2 finished with value: 0.3944766624011906 and parameters: {'learning_rate': 2.2506750661077515e-05, 'batch_size': 16, 'weight_decay': 0.016141925324305778}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8402\n",
            "  Validation F1 Score: 0.3945\n",
            "\n",
            "Trial 3:\n",
            "  Learning Rate: 6.810398432663404e-05\n",
            "  Batch Size: 32\n",
            "  Weight Decay: 0.002577966495717829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.6833\n",
            "  Epoch 2: Training Loss = 0.4287\n",
            "  Epoch 3: Training Loss = 0.1454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 04:06:42,642] Trial 3 finished with value: 0.582767475332997 and parameters: {'learning_rate': 6.810398432663404e-05, 'batch_size': 32, 'weight_decay': 0.002577966495717829}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8833\n",
            "  Validation F1 Score: 0.5828\n",
            "\n",
            "Trial 4:\n",
            "  Learning Rate: 5.946825651847558e-05\n",
            "  Batch Size: 16\n",
            "  Weight Decay: 0.006548308256690053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.5339\n",
            "  Epoch 2: Training Loss = 0.3882\n",
            "  Epoch 3: Training Loss = 0.1353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 04:25:18,526] Trial 4 finished with value: 0.41329425582570206 and parameters: {'learning_rate': 5.946825651847558e-05, 'batch_size': 16, 'weight_decay': 0.006548308256690053}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.9045\n",
            "  Validation F1 Score: 0.4133\n",
            "\n",
            "Trial 5:\n",
            "  Learning Rate: 6.0529375215779714e-05\n",
            "  Batch Size: 32\n",
            "  Weight Decay: 0.008603738297666154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.7466\n",
            "  Epoch 2: Training Loss = 0.4711\n",
            "  Epoch 3: Training Loss = 0.1705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 04:42:16,906] Trial 5 finished with value: 0.5728622521323612 and parameters: {'learning_rate': 6.0529375215779714e-05, 'batch_size': 32, 'weight_decay': 0.008603738297666154}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8768\n",
            "  Validation F1 Score: 0.5729\n",
            "\n",
            "Trial 6:\n",
            "  Learning Rate: 6.8429672141983e-05\n",
            "  Batch Size: 32\n",
            "  Weight Decay: 0.013040132330181801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.6860\n",
            "  Epoch 2: Training Loss = 0.4276\n",
            "  Epoch 3: Training Loss = 0.1472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 04:59:15,603] Trial 6 finished with value: 0.5806685637706727 and parameters: {'learning_rate': 6.8429672141983e-05, 'batch_size': 32, 'weight_decay': 0.013040132330181801}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8916\n",
            "  Validation F1 Score: 0.5807\n",
            "\n",
            "Trial 7:\n",
            "  Learning Rate: 2.264513834473916e-05\n",
            "  Batch Size: 32\n",
            "  Weight Decay: 0.01896378333767471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.2156\n",
            "  Epoch 2: Training Loss = 1.0107\n",
            "  Epoch 3: Training Loss = 0.5728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 05:16:14,349] Trial 7 finished with value: 0.5318022474763522 and parameters: {'learning_rate': 2.264513834473916e-05, 'batch_size': 32, 'weight_decay': 0.01896378333767471}. Best is trial 1 with value: 0.6832869192391429.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.7761\n",
            "  Validation F1 Score: 0.5318\n",
            "\n",
            "Trial 8:\n",
            "  Learning Rate: 7.647458264348458e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.010145868032051947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.8870\n",
            "  Epoch 2: Training Loss = 0.5454\n",
            "  Epoch 3: Training Loss = 0.2142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 05:32:28,881] Trial 8 finished with value: 0.7052491301275872 and parameters: {'learning_rate': 7.647458264348458e-05, 'batch_size': 64, 'weight_decay': 0.010145868032051947}. Best is trial 8 with value: 0.7052491301275872.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8740\n",
            "  Validation F1 Score: 0.7052\n",
            "\n",
            "Trial 9:\n",
            "  Learning Rate: 3.362765347630469e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 6.999172219382677e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.3193\n",
            "  Epoch 2: Training Loss = 1.0382\n",
            "  Epoch 3: Training Loss = 0.5909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 05:48:43,307] Trial 9 finished with value: 0.6334136041316071 and parameters: {'learning_rate': 3.362765347630469e-05, 'batch_size': 64, 'weight_decay': 6.999172219382677e-05}. Best is trial 8 with value: 0.7052491301275872.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.7682\n",
            "  Validation F1 Score: 0.6334\n",
            "\n",
            "Trial 10:\n",
            "  Learning Rate: 3.2352549870656554e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.009620449439701894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yzsHxGVwgMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training with Selected Hyperparameters"
      ],
      "metadata": {
        "id": "STTpv-iGqX1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "batch_size = 64\n",
        "# Update the DataLoader with the batch size\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "# Reinitialize the model, optimizer, and scheduler with the new hyperparameters\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=19,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=7.6e-05, # Tuned learning rate\n",
        "    eps=1e-8,  # Fixed epsilon\n",
        "    weight_decay=0.01,  # Tuned weight decay\n",
        ")\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),  # 10% warmup steps\n",
        "    num_training_steps=total_steps,\n",
        ")\n",
        "# Training loop\n",
        "import random\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Move batch tensors to the device\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = outputs.logits  # Extract logits from the model output\n",
        "\n",
        "        # Calculate loss using the custom loss function with class weights\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "    eval_accuracy, eval_f1 = 0, 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        # Move batch tensors to the device\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Forward pass\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        # Move logits and labels to CPU for metric calculation\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate accuracy and F1 score\n",
        "        eval_accuracy += flat_accuracy(logits, labels)\n",
        "        eval_f1 += flat_f1(logits, labels)\n",
        "\n",
        "    print(f\"Validation Accuracy: {eval_accuracy / len(val_dataloader)}\")\n",
        "    print(f\"Validation F1 Score: {eval_f1 / len(val_dataloader)}\")\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4838d098f6cd4efc881379497988edeb",
            "ee061e85713047849e4fdcf31287e4f6",
            "5f373218a5384f1f8d291a6e5d3a8e4d",
            "2e7e6848fd7942fb8f7990c5a5275d1f",
            "bdcbd04002d34053aeb5d682512294cf",
            "883700350e544e9581282426201b8149",
            "e954e8acccf04d1f9297f83b882b52fe",
            "fa3283265c584ff8a8f289d924fa138a",
            "8c19b4cabcb24f31bfe4a4aabb0a473a",
            "f9b3511817e84f7baaf7872ee9bbf154",
            "0bd5c0df8fa64af89ad28f096ff6b330"
          ]
        },
        "id": "0oJ0yo58qXg5",
        "outputId": "e8a8c382-3306-4107-a626-588997e2698c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4838d098f6cd4efc881379497988edeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.99\n",
            "  Training epoch took: 0:05:01\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.6693899782135077\n",
            "Validation F1 Score: 0.5427622130771617\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epoch took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8320057189542484\n",
            "Validation F1 Score: 0.6780302914596893\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epoch took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8625408496732027\n",
            "Validation F1 Score: 0.6870374561841547\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epoch took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8884463507625272\n",
            "Validation F1 Score: 0.7053086474459532\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epoch took: 0:05:04\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: 0.8994417211328977\n",
            "Validation F1 Score: 0.7130106724841184\n",
            "  Validation took: 0:00:12\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Evaluation"
      ],
      "metadata": {
        "id": "4OtSD4phYcW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "\n",
        "# Tokenize the test sentences and prepare the test DataLoader\n",
        "test_input_ids, test_attention_masks = Input_embeddings(test_cleaned['sentence'].values, max_length)\n",
        "test_labels = torch.tensor(test_cleaned['tag'].values)\n",
        "\n",
        "# Create the TensorDataset\n",
        "test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "# Create the DataLoader\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=64)"
      ],
      "metadata": {
        "id": "INIgJkVyqkMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test evaluation loop\n",
        "model.eval()\n",
        "test_accuracy, test_f1 = 0, 0\n",
        "nb_test_steps = 0\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    # Move batch to GPU\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        logits = outputs[0]\n",
        "\n",
        "    # Calculate predictions on GPU\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "    # Calculate accuracy on GPU\n",
        "    correct_predictions = torch.sum(preds == b_labels).item()\n",
        "    total_predictions = len(b_labels)\n",
        "    tmp_test_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Calculate F1 score on GPU (move to CPU temporarily for sklearn)\n",
        "    tmp_test_f1 = f1_score(\n",
        "        b_labels.cpu().numpy(),  # Move labels to CPU for sklearn\n",
        "        preds.cpu().numpy(),     # Move predictions to CPU for sklearn\n",
        "        average='macro',         # Macro-averaged F1 score\n",
        "        labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]  # Exclude 'Other' class\n",
        "    )\n",
        "\n",
        "    # Accumulate metrics\n",
        "    test_accuracy += tmp_test_accuracy\n",
        "    test_f1 += tmp_test_f1\n",
        "    nb_test_steps += 1\n",
        "\n",
        "# Report test metrics\n",
        "print(f\"Test Accuracy: {test_accuracy / nb_test_steps}\")\n",
        "print(f\"Test F1 Score (excluding 'Other' class): {test_f1 / nb_test_steps}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKIHZz8equkU",
        "outputId": "97b4a1a9-dbb7-4e76-a201-a84d18d76c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7951834402566159\n",
            "Test F1 Score (excluding 'Other' class): 0.661488059790204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'cw_ds_bert_model.pt')"
      ],
      "metadata": {
        "id": "Oesldg6cru88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Miscellaneous Hyperparameter Checks"
      ],
      "metadata": {
        "id": "jHEzNfc5TxMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna import Trial\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set a fixed random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial: Trial):\n",
        "    # Hyperparameters to tune\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 4e-5, 7e-5, log=True)  # Adjusted range\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 0.003, 0.009)  # Reduced range\n",
        "\n",
        "\n",
        "    batch_size = 64 #chosen\n",
        "    # Print the current combination of hyperparameters\n",
        "    print(f\"\\nTrial {trial.number}:\")\n",
        "    print(f\"  Learning Rate: {learning_rate}\")\n",
        "    print(f\"  Batch Size: {batch_size}\")\n",
        "    print(f\"  Weight Decay: {weight_decay}\")\n",
        "\n",
        "    # Update the DataLoader with the new batch size\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Reinitialize the model, optimizer, and scheduler with the new hyperparameters\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=19,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        eps=1e-8,  # Fixed epsilon\n",
        "        weight_decay=weight_decay,  # Tuned weight decay\n",
        "    )\n",
        "    total_steps = len(train_dataloader) * 3  # Fixed epochs = 3\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=int(0.1 * total_steps),  # 10% warmup steps\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    for epoch_i in range(3):  # Fixed epochs = 3\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"  Epoch {epoch_i + 1}: Training Loss = {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    eval_accuracy, eval_f1 = 0, 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "        eval_accuracy += flat_accuracy(logits, labels)\n",
        "        eval_f1 += flat_f1(logits, labels)\n",
        "\n",
        "    # Compute average validation metrics\n",
        "    avg_eval_accuracy = eval_accuracy / len(val_dataloader)\n",
        "    avg_eval_f1 = eval_f1 / len(val_dataloader)\n",
        "\n",
        "    # Print the validation metrics\n",
        "    print(f\"  Validation Accuracy: {avg_eval_accuracy:.4f}\")\n",
        "    print(f\"  Validation F1 Score: {avg_eval_f1:.4f}\")\n",
        "\n",
        "    # Return the metric to optimize (e.g., F1 score or a combination of accuracy and F1)\n",
        "    return avg_eval_f1\n",
        "\n",
        "# Create an Optuna study and optimize\n",
        "study = optuna.create_study(direction=\"maximize\")  # Maximize F1 score\n",
        "study.optimize(objective, n_trials=6)  # Limit to 15 combinations\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"\\nBest hyperparameters:\", study.best_params)\n",
        "print(\"Best F1 score:\", study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjWRHtc5T0rs",
        "outputId": "8f547599-d4eb-4088-f455-b833686d594e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 09:40:02,126] A new study created in memory with name: no-name-37bd19ca-a375-4720-86b1-502407366159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 0:\n",
            "  Learning Rate: 5.819578047519045e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.0031002403184018862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.0184\n",
            "  Epoch 2: Training Loss = 0.6087\n",
            "  Epoch 3: Training Loss = 0.2670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 09:57:25,280] Trial 0 finished with value: 0.6907141622055384 and parameters: {'learning_rate': 5.819578047519045e-05, 'weight_decay': 0.0031002403184018862}. Best is trial 0 with value: 0.6907141622055384.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8508\n",
            "  Validation F1 Score: 0.6907\n",
            "\n",
            "Trial 1:\n",
            "  Learning Rate: 4.076966194822149e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.003165006959976539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.1743\n",
            "  Epoch 2: Training Loss = 0.8719\n",
            "  Epoch 3: Training Loss = 0.4259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 10:14:49,216] Trial 1 finished with value: 0.6613305417731885 and parameters: {'learning_rate': 4.076966194822149e-05, 'weight_decay': 0.003165006959976539}. Best is trial 0 with value: 0.6907141622055384.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8052\n",
            "  Validation F1 Score: 0.6613\n",
            "\n",
            "Trial 2:\n",
            "  Learning Rate: 5.186460168977477e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.008800043328350281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.0171\n",
            "  Epoch 2: Training Loss = 0.7067\n",
            "  Epoch 3: Training Loss = 0.3208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 10:32:11,016] Trial 2 finished with value: 0.6748088999714874 and parameters: {'learning_rate': 5.186460168977477e-05, 'weight_decay': 0.008800043328350281}. Best is trial 0 with value: 0.6907141622055384.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8255\n",
            "  Validation F1 Score: 0.6748\n",
            "\n",
            "Trial 3:\n",
            "  Learning Rate: 5.6633075602830086e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.004270762866873623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 1.9868\n",
            "  Epoch 2: Training Loss = 0.6364\n",
            "  Epoch 3: Training Loss = 0.2714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 10:49:33,155] Trial 3 finished with value: 0.691240855049432 and parameters: {'learning_rate': 5.6633075602830086e-05, 'weight_decay': 0.004270762866873623}. Best is trial 3 with value: 0.691240855049432.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8406\n",
            "  Validation F1 Score: 0.6912\n",
            "\n",
            "Trial 4:\n",
            "  Learning Rate: 4.294485617125591e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.006966116640116172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Training Loss = 2.1387\n",
            "  Epoch 2: Training Loss = 0.7902\n",
            "  Epoch 3: Training Loss = 0.3862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-24 11:06:55,420] Trial 4 finished with value: 0.671895773798206 and parameters: {'learning_rate': 4.294485617125591e-05, 'weight_decay': 0.006966116640116172}. Best is trial 3 with value: 0.691240855049432.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Validation Accuracy: 0.8249\n",
            "  Validation F1 Score: 0.6719\n",
            "\n",
            "Trial 5:\n",
            "  Learning Rate: 6.7829159644573e-05\n",
            "  Batch Size: 64\n",
            "  Weight Decay: 0.0058995274228931275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fh8UYgnRU_Ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}